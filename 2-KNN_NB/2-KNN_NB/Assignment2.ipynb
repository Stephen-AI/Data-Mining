{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This assignment may be worked individually or in pairs. \n",
    "## Enter your name/names here:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# David Mao, dm46452\n",
    "# Stephen Aigbomian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Assignment 2: Naive Bayes and KNN classifier\n",
    "\n",
    "In this assignment you'll implement the Naive Bayes and KNN classifier to classify patients as either having or not having diabetic retinopathy. For this task we'll be using the same Diabetic Retinopathy data set which was used in the previous assignment on decision trees. The implementation details are up to you but, generally it is a good idea to divide your code up into helper functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Headers\n",
    "# You are welcome to add additional headers if you wish\n",
    "# EXCEPT for scikit-learn... You may NOT use scikit-learn for this assignment!\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from math import log, sqrt\n",
    "from random import shuffle\n",
    "from collections import OrderedDict, defaultdict\n",
    "import heapq\n",
    "from functools import reduce\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataPoint:\n",
    "    def __str__(self):\n",
    "        return \"< \" + str(self.label) + \": \" + str(self.features) + \" >\"\n",
    "    def __init__(self, label, features):\n",
    "        self.label = label # the classification label of this data point\n",
    "        self.features = features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the data from a CSV file. You may either put it into a list of `DataPoints` as you did on the previous assignment (class provided above), or you may choose to store it any any format you wish, like a Pandas dataframe, or any other format you'd like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>19</td>\n",
       "      <td>18</td>\n",
       "      <td>14</td>\n",
       "      <td>49.895756</td>\n",
       "      <td>17.775994</td>\n",
       "      <td>5.270920</td>\n",
       "      <td>0.771761</td>\n",
       "      <td>0.018632</td>\n",
       "      <td>0.006864</td>\n",
       "      <td>0.003923</td>\n",
       "      <td>0.003923</td>\n",
       "      <td>0.486903</td>\n",
       "      <td>0.100025</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>22</td>\n",
       "      <td>18</td>\n",
       "      <td>16</td>\n",
       "      <td>13</td>\n",
       "      <td>57.709936</td>\n",
       "      <td>23.799994</td>\n",
       "      <td>3.325423</td>\n",
       "      <td>0.234185</td>\n",
       "      <td>0.003903</td>\n",
       "      <td>0.003903</td>\n",
       "      <td>0.003903</td>\n",
       "      <td>0.003903</td>\n",
       "      <td>0.520908</td>\n",
       "      <td>0.144414</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>62</td>\n",
       "      <td>60</td>\n",
       "      <td>59</td>\n",
       "      <td>54</td>\n",
       "      <td>47</td>\n",
       "      <td>33</td>\n",
       "      <td>55.831441</td>\n",
       "      <td>27.993933</td>\n",
       "      <td>12.687485</td>\n",
       "      <td>4.852282</td>\n",
       "      <td>1.393889</td>\n",
       "      <td>0.373252</td>\n",
       "      <td>0.041817</td>\n",
       "      <td>0.007744</td>\n",
       "      <td>0.530904</td>\n",
       "      <td>0.128548</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "      <td>53</td>\n",
       "      <td>53</td>\n",
       "      <td>50</td>\n",
       "      <td>43</td>\n",
       "      <td>31</td>\n",
       "      <td>40.467228</td>\n",
       "      <td>18.445954</td>\n",
       "      <td>9.118901</td>\n",
       "      <td>3.079428</td>\n",
       "      <td>0.840261</td>\n",
       "      <td>0.272434</td>\n",
       "      <td>0.007653</td>\n",
       "      <td>0.001531</td>\n",
       "      <td>0.483284</td>\n",
       "      <td>0.114790</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>41</td>\n",
       "      <td>39</td>\n",
       "      <td>27</td>\n",
       "      <td>18.026254</td>\n",
       "      <td>8.570709</td>\n",
       "      <td>0.410381</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.475935</td>\n",
       "      <td>0.123572</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0   1   2   3   4   5   6   7          8          9          10        11  \\\n",
       "0   1   1  22  22  22  19  18  14  49.895756  17.775994   5.270920  0.771761   \n",
       "1   1   1  24  24  22  18  16  13  57.709936  23.799994   3.325423  0.234185   \n",
       "2   1   1  62  60  59  54  47  33  55.831441  27.993933  12.687485  4.852282   \n",
       "3   1   1  55  53  53  50  43  31  40.467228  18.445954   9.118901  3.079428   \n",
       "4   1   1  44  44  44  41  39  27  18.026254   8.570709   0.410381  0.000000   \n",
       "\n",
       "         12        13        14        15        16        17  18  19  \n",
       "0  0.018632  0.006864  0.003923  0.003923  0.486903  0.100025   1   0  \n",
       "1  0.003903  0.003903  0.003903  0.003903  0.520908  0.144414   0   0  \n",
       "2  1.393889  0.373252  0.041817  0.007744  0.530904  0.128548   0   1  \n",
       "3  0.840261  0.272434  0.007653  0.001531  0.483284  0.114790   0   0  \n",
       "4  0.000000  0.000000  0.000000  0.000000  0.475935  0.123572   0   1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame = pd.read_csv(\"messidor_features.txt\", header=None)\n",
    "data_frame.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Naive Bayes Classifier\n",
    "\n",
    "Naive Bayes (NB) classifier is a simple probabilistic classifier that is based on applying the Bayes' theorem and assumes a strong (naive) independence between features. The Diabetic Retinopath data set contains both categorical and continuous features. Dealing with categorical features has been already been discussed in detail in class. Continuous attributes, on the other hand, are more interesting to handle. Most commonly, this is done by assuming normal probability distribution over the feature values or by binning the attribute values in a fixed number of bins. In this assignment you'll be implementing the binning approach. For each continuous attribute, you'll construct 3 equal sized bins. For example, feature 5 ranges from `[1 - 120]` the 3 bins that you'll construct will be `[1 - 40]`, `[41 - 80]`, `[81 - 120]`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1. Implement a Naive Bayes classifier. Measure the accuracy of your classifier using 5-fold cross validation and display the confusion matrix. Also print the precision and recall for class label 1 (patients that have been diagnosed with the disease)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nd = pd.read_csv(\"messidor_features.txt\", header=None)\\ntest_set_len = len(d) // 5\\naccuracies = []\\nfor i in range(5):\\n# partition data into train_set and test_set\\n    train_set = d.loc[0:i * test_set_len] + d.loc[(i + 1) * test_set_len:len(d)]\\n    test_set = d.loc[i * test_set_len:(i + 1) * test_set_len]\\n\\n    print (\\'Training set size:\\', len(train_set))\\n    print (\\'Test set size    :\\', len(test_set))\\n\\n    # create the classifier\\n    bayes = Naive_Bayes_Classifier(train_set)\\n    bayes.train()\\n\\n    # calculate the accuracy of the classifier\\n    accuracy = calcAccuracy(bayes, test_set)\\n    accuracies.append(accuracy)\\n    print (\\'The accuracy on the test set \\', i, \\' is \\', str(accuracy * 100.0))\\navg_accuracy = sum(accuracies) / len(accuracies)\\nprint (\\'The average accuracy on the data set is: \\', str(avg_accuracy))\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code goes here\n",
    "\n",
    "binary_features = (0, 1, 18, 19)\n",
    "\"\"\"\n",
    "class Naive_Bayes_Classifier:\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        self.cond_pos = []\n",
    "        self.cond_neg = []\n",
    "    \n",
    "    def compute_conditionals(self, classification, feature_index):\n",
    "        data = self.data[self.data[19] == classification]\n",
    "        if feature_index in binary_features:\n",
    "            num_pos, num_neg = self.compute_binary_prop(data, feature_index)\n",
    "            if classification:\n",
    "                self.cond_pos.append({1: num_pos, 0: num_neg})\n",
    "            else:\n",
    "                self.cond_neg.append({1: num_pos, 0: num_neg})\n",
    "        else:\n",
    "            props = self.compute_cont_prop(data, feature_index)\n",
    "            if classification:\n",
    "                self.cond_pos.append(props)\n",
    "            else:\n",
    "                self.cond_pos.append(props)\n",
    "    \n",
    "    def compute_binary_prop(self, data, feature_index):\n",
    "        length = data[feature_index].count()\n",
    "        num_pos = data[data[feature_index] == 1].count()\n",
    "        return (num_pos, length - num_pos)\n",
    "    \n",
    "    def compute_cont_prop(self, data, feature_index):\n",
    "        feature_min = data[feature_index].min()\n",
    "        feature_max = data[feature_index].max()\n",
    "        bin_size = (feature_max - feature_min) / 3\n",
    "        bins = []\n",
    "        start = feature_min\n",
    "        end = feature_min + bin_size\n",
    "        for i in range(3):\n",
    "            bins.append((start, end))\n",
    "            start += bin_size\n",
    "            end += bin_size\n",
    "        props = OrderedDict()\n",
    "        \n",
    "        for i in range(3):\n",
    "            cur_bin = bins[i]\n",
    "            bin_start, bin_end = cur_bin\n",
    "            if i < 2:\n",
    "                props[(bin_start, bin_end)] = data[bin_start <= data[feature_index] & data[feature_index] < bin_end].count()\n",
    "            else:\n",
    "                props[(bin_start, bin_end)] = data[bin_start <= data[feature_index] & data[feature_index] <= bin_end].count()\n",
    "        return props\n",
    "    \n",
    "    def train(self):\n",
    "        for i in range(19):\n",
    "            self.compute_conditionals(1, i);\n",
    "            self.compute_conditionals(0, i)\n",
    "    \n",
    "    def calculate_prob(self, data_point, label):\n",
    "        props = []\n",
    "        if label:\n",
    "            props = self.cond_pos\n",
    "        else:\n",
    "            props = self.cond_neg\n",
    "        \n",
    "        prob = 1.0\n",
    "        for index, feature in enumerate(data_point):\n",
    "            feature_props = self.cond_pos[index]\n",
    "            if index in binary_features:\n",
    "                if feature:\n",
    "                    prob *= feature_props[1] / sum(feature_props.values())\n",
    "                else:\n",
    "                    prob *= feature_props[0] / sum(feature_props.values())\n",
    "            else:\n",
    "                for index, cur_bin in enumerate(feature_props.keys()):\n",
    "                    bin_start, bin_end = cur_bin\n",
    "                    if index < 2:\n",
    "                        if bin_start <= feature < bin_end:\n",
    "                            prob *= feature_props[cur_bin] / sum(feature_props.values())\n",
    "                    else:\n",
    "                        if bin_start <= feature <= bin_end:\n",
    "                            prob *= feature_props[cur_bin] / sum(feature_props.values())\n",
    "        \n",
    "    def classify(self, data_point):\n",
    "        prob_pos = self.calculate_prob(data_point, 1)\n",
    "        prob_neg = self.calculate_prob(data_point, 0)\n",
    "        return 1 if prob_pos > prob_neg else 0\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "d = pd.read_csv(\"messidor_features.txt\", header=None)\n",
    "test_set_len = len(d) // 5\n",
    "accuracies = []\n",
    "for i in range(5):\n",
    "# partition data into train_set and test_set\n",
    "    train_set = d.loc[0:i * test_set_len] + d.loc[(i + 1) * test_set_len:len(d)]\n",
    "    test_set = d.loc[i * test_set_len:(i + 1) * test_set_len]\n",
    "\n",
    "    print ('Training set size:', len(train_set))\n",
    "    print ('Test set size    :', len(test_set))\n",
    "\n",
    "    # create the classifier\n",
    "    bayes = Naive_Bayes_Classifier(train_set)\n",
    "    bayes.train()\n",
    "\n",
    "    # calculate the accuracy of the classifier\n",
    "    accuracy = calcAccuracy(bayes, test_set)\n",
    "    accuracies.append(accuracy)\n",
    "    print ('The accuracy on the test set ', i, ' is ', str(accuracy * 100.0))\n",
    "avg_accuracy = sum(accuracies) / len(accuracies)\n",
    "print ('The average accuracy on the data set is: ', str(avg_accuracy))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Part 2: K Nearest Neighbor (KNN) Classifier\n",
    "\n",
    "The KNN classifier consists of two stages:-\n",
    "- In the training stage, the classifier takes the training data and simply memorizes it\n",
    "- In the test stage, the classifier compares the test data with the training data and simply returns the maximum occuring label of the k nearest data points.\n",
    "\n",
    "The distance calculation method is central to the algorithm, typically Euclidean distance is used but other distance metrics like Manhattan distance can also be used. In this assignment you'll be implementing the classifier using the Euclidean distance metric. It is important to note that, Euclidean distance is very sensitive to the scaling of different attributes hence, before you can build your classifier you have to normalize the values of each feature in the data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2. Normalize the dataset so that each feature value lies between `[0-1]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.140000</td>\n",
       "      <td>0.160305</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.173077</td>\n",
       "      <td>0.177083</td>\n",
       "      <td>0.147727</td>\n",
       "      <td>0.122764</td>\n",
       "      <td>0.106359</td>\n",
       "      <td>0.049693</td>\n",
       "      <td>0.012913</td>\n",
       "      <td>0.000362</td>\n",
       "      <td>0.000342</td>\n",
       "      <td>0.000661</td>\n",
       "      <td>0.001271</td>\n",
       "      <td>0.530801</td>\n",
       "      <td>0.261133</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.153333</td>\n",
       "      <td>0.175573</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.163462</td>\n",
       "      <td>0.156250</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.142126</td>\n",
       "      <td>0.142403</td>\n",
       "      <td>0.031351</td>\n",
       "      <td>0.003918</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.000657</td>\n",
       "      <td>0.001264</td>\n",
       "      <td>0.682302</td>\n",
       "      <td>0.536341</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.406667</td>\n",
       "      <td>0.450382</td>\n",
       "      <td>0.487395</td>\n",
       "      <td>0.509615</td>\n",
       "      <td>0.479167</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.137472</td>\n",
       "      <td>0.167497</td>\n",
       "      <td>0.119614</td>\n",
       "      <td>0.081188</td>\n",
       "      <td>0.027106</td>\n",
       "      <td>0.018571</td>\n",
       "      <td>0.007043</td>\n",
       "      <td>0.002509</td>\n",
       "      <td>0.726836</td>\n",
       "      <td>0.437973</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.360000</td>\n",
       "      <td>0.396947</td>\n",
       "      <td>0.436975</td>\n",
       "      <td>0.471154</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.340909</td>\n",
       "      <td>0.099403</td>\n",
       "      <td>0.110368</td>\n",
       "      <td>0.085971</td>\n",
       "      <td>0.051525</td>\n",
       "      <td>0.016340</td>\n",
       "      <td>0.013555</td>\n",
       "      <td>0.001289</td>\n",
       "      <td>0.000496</td>\n",
       "      <td>0.514678</td>\n",
       "      <td>0.352675</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.286667</td>\n",
       "      <td>0.328244</td>\n",
       "      <td>0.361345</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.395833</td>\n",
       "      <td>0.295455</td>\n",
       "      <td>0.043799</td>\n",
       "      <td>0.051281</td>\n",
       "      <td>0.003869</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.481936</td>\n",
       "      <td>0.407122</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0   1         2         3         4         5         6         7   \\\n",
       "0   1   1  0.140000  0.160305  0.176471  0.173077  0.177083  0.147727   \n",
       "1   1   1  0.153333  0.175573  0.176471  0.163462  0.156250  0.136364   \n",
       "2   1   1  0.406667  0.450382  0.487395  0.509615  0.479167  0.363636   \n",
       "3   1   1  0.360000  0.396947  0.436975  0.471154  0.437500  0.340909   \n",
       "4   1   1  0.286667  0.328244  0.361345  0.384615  0.395833  0.295455   \n",
       "\n",
       "         8         9         10        11        12        13        14  \\\n",
       "0  0.122764  0.106359  0.049693  0.012913  0.000362  0.000342  0.000661   \n",
       "1  0.142126  0.142403  0.031351  0.003918  0.000076  0.000194  0.000657   \n",
       "2  0.137472  0.167497  0.119614  0.081188  0.027106  0.018571  0.007043   \n",
       "3  0.099403  0.110368  0.085971  0.051525  0.016340  0.013555  0.001289   \n",
       "4  0.043799  0.051281  0.003869  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "         15        16        17  18  19  \n",
       "0  0.001271  0.530801  0.261133   1   0  \n",
       "1  0.001264  0.682302  0.536341   0   0  \n",
       "2  0.002509  0.726836  0.437973   0   1  \n",
       "3  0.000496  0.514678  0.352675   0   0  \n",
       "4  0.000000  0.481936  0.407122   0   1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code goes here\n",
    "knn_data = data_frame.copy()\n",
    "\n",
    "def normalize(val, col_min, col_max):\n",
    "    return (val - col_min) / (col_max - col_min)\n",
    "\n",
    "for col_index in knn_data:\n",
    "    if col_index in binary_features:\n",
    "        continue\n",
    "    col_min = knn_data[col_index].min()\n",
    "    col_max = knn_data[col_index].max()\n",
    "    knn_data[col_index] = knn_data[col_index].map(lambda x: normalize(x, col_min, col_max))\n",
    "\n",
    "knn_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3. Build your KNN classifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code goes here\n",
    "\n",
    "def calc_dist(data_1, data_2):\n",
    "    dist = 0.0\n",
    "    for index in range(19):\n",
    "        dist += (data_1[index] - data_2[index]) ** 2\n",
    "    return sqrt(dist)\n",
    "    \n",
    "    \n",
    "class KNN:\n",
    "    def __init__(self, data, k):\n",
    "        self.data = data\n",
    "        self.k = k\n",
    "    \n",
    "    def classify(self, data_point):\n",
    "        nearest_neighbors = []\n",
    "        num_pos = 0\n",
    "        for index, datum in self.data.iterrows():\n",
    "            euc_dist = calc_dist(datum, data_point)\n",
    "            if len(nearest_neighbors) < self.k:\n",
    "                # heap insertion, use -euc_dist because heapq is min heap\n",
    "                heapq.heappush(nearest_neighbors, (-euc_dist, datum[19]))\n",
    "                num_pos += datum[19]\n",
    "            else:\n",
    "                # compare euc dist to largest value in heap\n",
    "                if euc_dist < abs(nearest_neighbors[0][0]):\n",
    "                    num_pos -= nearest_neighbors[0][1]\n",
    "                    heapq.heappop(nearest_neighbors)\n",
    "                    heapq.heappush(nearest_neighbors, (-euc_dist, datum[19]))\n",
    "                    num_pos += datum[19]\n",
    "        \n",
    "        return 1 if num_pos > (self.k // 2) else 0\n",
    "\n",
    "def calcAccuracy(classifier, data):\n",
    "    total = 0\n",
    "    num_correct = 0\n",
    "    for index, data_point in data.iterrows():\n",
    "        if classifier.classify(data_point) == data_point[19]:\n",
    "            num_correct += 1\n",
    "        total += 1\n",
    "    \n",
    "    return num_correct / total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q4. Find the best value of k using 5-fold cross validation. In each fold of CV, divide your data into a training set and a validation set. Try k ranging from 1 to 10 and plot the accuracies using 5-fold CV. Use this plot to identify the best value of k (provide reasoning)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0   1         2         3         4         5         6         7   \\\n",
      "230   1   1  0.073333  0.083969  0.092437  0.096154  0.083333  0.034091   \n",
      "231   1   1  0.100000  0.106870  0.117647  0.125000  0.125000  0.090909   \n",
      "232   1   1  0.453333  0.496183  0.487395  0.403846  0.312500  0.204545   \n",
      "233   1   1  0.293333  0.335878  0.369748  0.423077  0.427083  0.352273   \n",
      "234   1   1  0.593333  0.641221  0.655462  0.692308  0.677083  0.590909   \n",
      "\n",
      "           8         9         10        11        12        13        14  \\\n",
      "230  0.032252  0.012131  0.004216  0.000069  0.000000  0.000000  0.000000   \n",
      "231  0.157504  0.194013  0.026912  0.001177  0.000057  0.000097  0.000329   \n",
      "232  0.400284  0.139924  0.118587  0.028025  0.003534  0.000000  0.000000   \n",
      "233  0.051505  0.040133  0.005248  0.000334  0.000000  0.000000  0.000000   \n",
      "234  0.088651  0.122714  0.098548  0.137785  0.126349  0.239625  0.574472   \n",
      "\n",
      "           15        16        17  18  19  \n",
      "230  0.000000  0.771540  0.181347   1   0  \n",
      "231  0.000633  0.712602  0.398083   0   0  \n",
      "232  0.000000  0.642699  0.421413   1   1  \n",
      "233  0.000000  0.771977  0.306517   0   0  \n",
      "234  0.622718  0.536549  0.407104   0   1  \n",
      "   0   1         2         3         4         5         6         7   \\\n",
      "0   1   1  0.140000  0.160305  0.176471  0.173077  0.177083  0.147727   \n",
      "1   1   1  0.153333  0.175573  0.176471  0.163462  0.156250  0.136364   \n",
      "2   1   1  0.406667  0.450382  0.487395  0.509615  0.479167  0.363636   \n",
      "3   1   1  0.360000  0.396947  0.436975  0.471154  0.437500  0.340909   \n",
      "4   1   1  0.286667  0.328244  0.361345  0.384615  0.395833  0.295455   \n",
      "\n",
      "         8         9         10        11        12        13        14  \\\n",
      "0  0.122764  0.106359  0.049693  0.012913  0.000362  0.000342  0.000661   \n",
      "1  0.142126  0.142403  0.031351  0.003918  0.000076  0.000194  0.000657   \n",
      "2  0.137472  0.167497  0.119614  0.081188  0.027106  0.018571  0.007043   \n",
      "3  0.099403  0.110368  0.085971  0.051525  0.016340  0.013555  0.001289   \n",
      "4  0.043799  0.051281  0.003869  0.000000  0.000000  0.000000  0.000000   \n",
      "\n",
      "         15        16        17  18  19  \n",
      "0  0.001271  0.530801  0.261133   1   0  \n",
      "1  0.001264  0.682302  0.536341   0   0  \n",
      "2  0.002509  0.726836  0.437973   0   1  \n",
      "3  0.000496  0.514678  0.352675   0   0  \n",
      "4  0.000000  0.481936  0.407122   0   1  \n",
      "Training set size: 921\n",
      "Test set size    : 230\n",
      "insertion took  0.217254638671875  time\n",
      "insertion took  0.24583983421325684  time\n",
      "insertion took  0.21941637992858887  time\n",
      "insertion took  0.2249011993408203  time\n",
      "insertion took  0.2342827320098877  time\n",
      "insertion took  0.2229175567626953  time\n",
      "insertion took  0.2246403694152832  time\n",
      "insertion took  0.23690009117126465  time\n",
      "insertion took  0.21937012672424316  time\n",
      "insertion took  0.2215101718902588  time\n",
      "insertion took  0.22390365600585938  time\n",
      "insertion took  0.21830487251281738  time\n",
      "insertion took  0.22220325469970703  time\n",
      "insertion took  0.2593204975128174  time\n",
      "insertion took  0.22308707237243652  time\n",
      "insertion took  0.22326302528381348  time\n",
      "insertion took  0.22411108016967773  time\n",
      "insertion took  0.2233119010925293  time\n",
      "insertion took  0.21839570999145508  time\n",
      "insertion took  0.22256755828857422  time\n",
      "insertion took  0.22386980056762695  time\n",
      "insertion took  0.2259976863861084  time\n",
      "insertion took  0.2265479564666748  time\n",
      "insertion took  0.2238614559173584  time\n",
      "insertion took  0.2404313087463379  time\n",
      "insertion took  0.2439436912536621  time\n",
      "insertion took  0.22397422790527344  time\n",
      "insertion took  0.2222766876220703  time\n",
      "insertion took  0.21994614601135254  time\n",
      "insertion took  0.22236156463623047  time\n",
      "insertion took  0.22755098342895508  time\n",
      "insertion took  0.21937966346740723  time\n",
      "insertion took  0.2217564582824707  time\n",
      "insertion took  0.2205352783203125  time\n",
      "insertion took  0.22579073905944824  time\n",
      "insertion took  0.21858644485473633  time\n",
      "insertion took  0.21917200088500977  time\n",
      "insertion took  0.2214806079864502  time\n",
      "insertion took  0.23938202857971191  time\n",
      "insertion took  0.22037029266357422  time\n",
      "insertion took  0.22184443473815918  time\n",
      "insertion took  0.21760916709899902  time\n",
      "insertion took  0.22230839729309082  time\n",
      "insertion took  0.24089455604553223  time\n",
      "insertion took  0.23749184608459473  time\n",
      "insertion took  0.2559943199157715  time\n",
      "insertion took  0.23958945274353027  time\n",
      "insertion took  0.24487781524658203  time\n",
      "insertion took  0.24042129516601562  time\n",
      "insertion took  0.24597668647766113  time\n",
      "insertion took  0.2269580364227295  time\n",
      "insertion took  0.22756695747375488  time\n",
      "insertion took  0.22721004486083984  time\n",
      "insertion took  0.21969127655029297  time\n",
      "insertion took  0.23280644416809082  time\n",
      "insertion took  0.22098827362060547  time\n",
      "insertion took  0.22344756126403809  time\n",
      "insertion took  0.2223949432373047  time\n",
      "insertion took  0.22307658195495605  time\n",
      "insertion took  0.22375249862670898  time\n",
      "insertion took  0.22328948974609375  time\n",
      "insertion took  0.2223827838897705  time\n",
      "insertion took  0.22142577171325684  time\n",
      "insertion took  0.2176980972290039  time\n",
      "insertion took  0.22066998481750488  time\n",
      "insertion took  0.22415971755981445  time\n",
      "insertion took  0.22210144996643066  time\n",
      "insertion took  0.2200024127960205  time\n",
      "insertion took  0.21811270713806152  time\n",
      "insertion took  0.2217845916748047  time\n",
      "insertion took  0.22036314010620117  time\n",
      "insertion took  0.22062373161315918  time\n",
      "insertion took  0.21740484237670898  time\n",
      "insertion took  0.22111105918884277  time\n",
      "insertion took  0.21907925605773926  time\n",
      "insertion took  0.2218630313873291  time\n",
      "insertion took  0.21937894821166992  time\n",
      "insertion took  0.22021961212158203  time\n",
      "insertion took  0.22045660018920898  time\n",
      "insertion took  0.21773624420166016  time\n",
      "insertion took  0.2202305793762207  time\n",
      "insertion took  0.219895601272583  time\n",
      "insertion took  0.21879291534423828  time\n",
      "insertion took  0.22073698043823242  time\n",
      "insertion took  0.21830487251281738  time\n",
      "insertion took  0.21857547760009766  time\n",
      "insertion took  0.21981501579284668  time\n",
      "insertion took  0.22034764289855957  time\n",
      "insertion took  0.22182917594909668  time\n",
      "insertion took  0.22144103050231934  time\n",
      "insertion took  0.22158527374267578  time\n",
      "insertion took  0.2198951244354248  time\n",
      "insertion took  0.22452187538146973  time\n",
      "insertion took  0.22359585762023926  time\n",
      "insertion took  0.21847152709960938  time\n",
      "insertion took  0.2207186222076416  time\n",
      "insertion took  0.22075676918029785  time\n",
      "insertion took  0.21795105934143066  time\n",
      "insertion took  0.22003722190856934  time\n",
      "insertion took  0.22083640098571777  time\n",
      "insertion took  0.2199711799621582  time\n",
      "insertion took  0.22152161598205566  time\n",
      "insertion took  0.2207794189453125  time\n",
      "insertion took  0.21841049194335938  time\n",
      "insertion took  0.21815896034240723  time\n",
      "insertion took  0.2223670482635498  time\n",
      "insertion took  0.21700072288513184  time\n",
      "insertion took  0.219024658203125  time\n",
      "insertion took  0.22163772583007812  time\n",
      "insertion took  0.2209475040435791  time\n",
      "insertion took  0.23218345642089844  time\n",
      "insertion took  0.21960663795471191  time\n",
      "insertion took  0.21885967254638672  time\n",
      "insertion took  0.21892404556274414  time\n",
      "insertion took  0.21931052207946777  time\n",
      "insertion took  0.21962285041809082  time\n",
      "insertion took  0.21664166450500488  time\n",
      "insertion took  0.21775221824645996  time\n",
      "insertion took  0.2168583869934082  time\n",
      "insertion took  0.22046947479248047  time\n",
      "insertion took  0.22213530540466309  time\n",
      "insertion took  0.216841459274292  time\n",
      "insertion took  0.21875214576721191  time\n",
      "insertion took  0.22053909301757812  time\n",
      "insertion took  0.21740412712097168  time\n",
      "insertion took  0.21855640411376953  time\n",
      "insertion took  0.22174382209777832  time\n",
      "insertion took  0.21872615814208984  time\n",
      "insertion took  0.22375059127807617  time\n",
      "insertion took  0.22040247917175293  time\n",
      "insertion took  0.21965670585632324  time\n",
      "insertion took  0.22163009643554688  time\n",
      "insertion took  0.22199296951293945  time\n",
      "insertion took  0.21785926818847656  time\n",
      "insertion took  0.2204573154449463  time\n",
      "insertion took  0.22132444381713867  time\n",
      "insertion took  0.22056078910827637  time\n",
      "insertion took  0.22072315216064453  time\n",
      "insertion took  0.21651792526245117  time\n",
      "insertion took  0.22098016738891602  time\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "insertion took  0.22228336334228516  time\n",
      "insertion took  0.21923089027404785  time\n",
      "insertion took  0.21869874000549316  time\n",
      "insertion took  0.2189779281616211  time\n",
      "insertion took  0.23119091987609863  time\n",
      "insertion took  0.22016167640686035  time\n",
      "insertion took  0.21983957290649414  time\n",
      "insertion took  0.21892547607421875  time\n",
      "insertion took  0.22089457511901855  time\n",
      "insertion took  0.22304344177246094  time\n",
      "insertion took  0.2300560474395752  time\n",
      "insertion took  0.22022080421447754  time\n",
      "insertion took  0.22085952758789062  time\n",
      "insertion took  0.21935009956359863  time\n",
      "insertion took  0.22118234634399414  time\n",
      "insertion took  0.22393393516540527  time\n",
      "insertion took  0.21835589408874512  time\n",
      "insertion took  0.22022509574890137  time\n",
      "insertion took  0.22030949592590332  time\n",
      "insertion took  0.21898555755615234  time\n",
      "insertion took  0.22150397300720215  time\n",
      "insertion took  0.22348785400390625  time\n",
      "insertion took  0.22225642204284668  time\n",
      "insertion took  0.22088932991027832  time\n",
      "insertion took  0.22441554069519043  time\n",
      "insertion took  0.21836566925048828  time\n",
      "insertion took  0.22175812721252441  time\n",
      "insertion took  0.22491693496704102  time\n",
      "insertion took  0.21713948249816895  time\n",
      "insertion took  0.22359728813171387  time\n",
      "insertion took  0.21958184242248535  time\n",
      "insertion took  0.2208423614501953  time\n",
      "insertion took  0.21826958656311035  time\n",
      "insertion took  0.22067666053771973  time\n",
      "insertion took  0.22079229354858398  time\n",
      "insertion took  0.21933388710021973  time\n",
      "insertion took  0.21880698204040527  time\n",
      "insertion took  0.2213149070739746  time\n",
      "insertion took  0.22050070762634277  time\n",
      "insertion took  0.22026753425598145  time\n",
      "insertion took  0.22189760208129883  time\n",
      "insertion took  0.22043299674987793  time\n",
      "insertion took  0.21922659873962402  time\n",
      "insertion took  0.22124576568603516  time\n",
      "insertion took  0.21994781494140625  time\n",
      "insertion took  0.21752095222473145  time\n",
      "insertion took  0.22275114059448242  time\n",
      "insertion took  0.22345948219299316  time\n",
      "insertion took  0.2205815315246582  time\n",
      "insertion took  0.21860814094543457  time\n",
      "insertion took  0.2186598777770996  time\n",
      "insertion took  0.2193307876586914  time\n",
      "insertion took  0.21790027618408203  time\n",
      "insertion took  0.22021794319152832  time\n",
      "insertion took  0.2181100845336914  time\n",
      "insertion took  0.22263002395629883  time\n",
      "insertion took  0.24685978889465332  time\n",
      "insertion took  0.22469282150268555  time\n",
      "insertion took  0.24452590942382812  time\n",
      "insertion took  0.2570760250091553  time\n",
      "insertion took  0.22306370735168457  time\n",
      "insertion took  0.2214806079864502  time\n",
      "insertion took  0.22302556037902832  time\n",
      "insertion took  0.22063875198364258  time\n",
      "insertion took  0.22501921653747559  time\n",
      "insertion took  0.22569847106933594  time\n",
      "insertion took  0.2204301357269287  time\n",
      "insertion took  0.22157859802246094  time\n",
      "insertion took  0.22689557075500488  time\n",
      "insertion took  0.21924924850463867  time\n",
      "insertion took  0.2223951816558838  time\n",
      "insertion took  0.2565300464630127  time\n",
      "insertion took  0.23879003524780273  time\n",
      "insertion took  0.22556853294372559  time\n",
      "insertion took  0.2212207317352295  time\n",
      "insertion took  0.2219841480255127  time\n",
      "insertion took  0.22106385231018066  time\n",
      "insertion took  0.22397541999816895  time\n",
      "insertion took  0.22147798538208008  time\n",
      "insertion took  0.21906065940856934  time\n",
      "insertion took  0.22101712226867676  time\n",
      "insertion took  0.22175884246826172  time\n",
      "insertion took  0.22369790077209473  time\n",
      "insertion took  0.21956324577331543  time\n",
      "insertion took  0.21748781204223633  time\n",
      "insertion took  0.22060728073120117  time\n",
      "insertion took  0.22090649604797363  time\n",
      "insertion took  0.22113656997680664  time\n",
      "insertion took  0.2198479175567627  time\n",
      "insertion took  0.21703600883483887  time\n",
      "Time taken: 51.34484624862671\n",
      "accuracy:  0.591304347826087\n",
      "insertion took  0.21986675262451172  time\n",
      "insertion took  0.21835613250732422  time\n",
      "insertion took  0.22097396850585938  time\n",
      "insertion took  0.22559571266174316  time\n",
      "insertion took  0.23782920837402344  time\n",
      "insertion took  0.24642014503479004  time\n",
      "insertion took  0.22724628448486328  time\n",
      "insertion took  0.22908473014831543  time\n",
      "insertion took  0.2361924648284912  time\n",
      "insertion took  0.23287415504455566  time\n",
      "insertion took  0.2351069450378418  time\n",
      "insertion took  0.23441648483276367  time\n",
      "insertion took  0.24030780792236328  time\n",
      "insertion took  0.23545575141906738  time\n",
      "insertion took  0.2306382656097412  time\n",
      "insertion took  0.22924232482910156  time\n",
      "insertion took  0.2327413558959961  time\n",
      "insertion took  0.21810269355773926  time\n",
      "insertion took  0.22043156623840332  time\n",
      "insertion took  0.22443294525146484  time\n",
      "insertion took  0.2216508388519287  time\n",
      "insertion took  0.22304964065551758  time\n",
      "insertion took  0.22173595428466797  time\n",
      "insertion took  0.22323822975158691  time\n",
      "insertion took  0.23917579650878906  time\n",
      "insertion took  0.22286081314086914  time\n",
      "insertion took  0.24313116073608398  time\n",
      "insertion took  0.21591949462890625  time\n",
      "insertion took  0.2216343879699707  time\n",
      "insertion took  0.22226595878601074  time\n",
      "insertion took  0.22109484672546387  time\n",
      "insertion took  0.21938514709472656  time\n",
      "insertion took  0.22393560409545898  time\n",
      "insertion took  0.22216486930847168  time\n",
      "insertion took  0.23047471046447754  time\n",
      "insertion took  0.2518143653869629  time\n",
      "insertion took  0.22617316246032715  time\n",
      "insertion took  0.22839617729187012  time\n",
      "insertion took  0.21829533576965332  time\n",
      "insertion took  0.21860003471374512  time\n",
      "insertion took  0.2196500301361084  time\n",
      "insertion took  0.2216038703918457  time\n",
      "insertion took  0.22386407852172852  time\n",
      "insertion took  0.22139835357666016  time\n",
      "insertion took  0.21951651573181152  time\n",
      "insertion took  0.2240161895751953  time\n",
      "insertion took  0.22534418106079102  time\n",
      "insertion took  0.2167963981628418  time\n",
      "insertion took  0.21834635734558105  time\n",
      "insertion took  0.22547507286071777  time\n",
      "insertion took  0.2203965187072754  time\n",
      "insertion took  0.22163701057434082  time\n",
      "insertion took  0.22040486335754395  time\n",
      "insertion took  0.22229623794555664  time\n",
      "insertion took  0.22371506690979004  time\n",
      "insertion took  0.22040057182312012  time\n",
      "insertion took  0.22097492218017578  time\n",
      "insertion took  0.22019410133361816  time\n",
      "insertion took  0.21780037879943848  time\n",
      "insertion took  0.22846341133117676  time\n",
      "insertion took  0.23395252227783203  time\n",
      "insertion took  0.21826672554016113  time\n",
      "insertion took  0.22544527053833008  time\n",
      "insertion took  0.21918773651123047  time\n",
      "insertion took  0.22532272338867188  time\n",
      "insertion took  0.22122597694396973  time\n",
      "insertion took  0.22071433067321777  time\n",
      "insertion took  0.22032690048217773  time\n",
      "insertion took  0.21956396102905273  time\n",
      "insertion took  0.21847295761108398  time\n",
      "insertion took  0.21530508995056152  time\n",
      "insertion took  0.22048187255859375  time\n",
      "insertion took  0.21886348724365234  time\n",
      "insertion took  0.21723246574401855  time\n",
      "insertion took  0.2194676399230957  time\n",
      "insertion took  0.22042059898376465  time\n",
      "insertion took  0.21924853324890137  time\n",
      "insertion took  0.21714496612548828  time\n",
      "insertion took  0.2197551727294922  time\n",
      "insertion took  0.21669650077819824  time\n",
      "insertion took  0.21837663650512695  time\n",
      "insertion took  0.21935796737670898  time\n",
      "insertion took  0.21821093559265137  time\n",
      "insertion took  0.21762895584106445  time\n",
      "insertion took  0.2185370922088623  time\n",
      "insertion took  0.21934294700622559  time\n",
      "insertion took  0.2182471752166748  time\n",
      "insertion took  0.21881961822509766  time\n",
      "insertion took  0.22037196159362793  time\n",
      "insertion took  0.2174851894378662  time\n",
      "insertion took  0.21917366981506348  time\n",
      "insertion took  0.21853303909301758  time\n",
      "insertion took  0.21853089332580566  time\n",
      "insertion took  0.21979594230651855  time\n",
      "insertion took  0.21912717819213867  time\n",
      "insertion took  0.21914958953857422  time\n",
      "insertion took  0.21684694290161133  time\n",
      "insertion took  0.22002005577087402  time\n",
      "insertion took  0.2202930450439453  time\n",
      "insertion took  0.21893596649169922  time\n",
      "insertion took  0.2185840606689453  time\n",
      "insertion took  0.21877145767211914  time\n",
      "insertion took  0.2189178466796875  time\n",
      "insertion took  0.21710824966430664  time\n",
      "insertion took  0.2178192138671875  time\n",
      "insertion took  0.22012948989868164  time\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "insertion took  0.22409391403198242  time\n",
      "insertion took  0.2185227870941162  time\n",
      "insertion took  0.21946096420288086  time\n",
      "insertion took  0.22067832946777344  time\n",
      "insertion took  0.21947002410888672  time\n",
      "insertion took  0.2155013084411621  time\n",
      "insertion took  0.22148823738098145  time\n",
      "insertion took  0.21785807609558105  time\n",
      "insertion took  0.21963787078857422  time\n",
      "insertion took  0.21537995338439941  time\n",
      "insertion took  0.21845602989196777  time\n",
      "insertion took  0.21754074096679688  time\n",
      "insertion took  0.21903085708618164  time\n",
      "insertion took  0.21738886833190918  time\n",
      "insertion took  0.21843838691711426  time\n",
      "insertion took  0.217437744140625  time\n",
      "insertion took  0.21816730499267578  time\n",
      "insertion took  0.21734833717346191  time\n",
      "insertion took  0.21627473831176758  time\n",
      "insertion took  0.2173161506652832  time\n",
      "insertion took  0.22388291358947754  time\n",
      "insertion took  0.2175757884979248  time\n",
      "insertion took  0.2189788818359375  time\n",
      "insertion took  0.22077417373657227  time\n",
      "insertion took  0.21774578094482422  time\n",
      "insertion took  0.22101116180419922  time\n",
      "insertion took  0.22443890571594238  time\n",
      "insertion took  0.22132611274719238  time\n",
      "insertion took  0.22502875328063965  time\n",
      "insertion took  0.22194910049438477  time\n",
      "insertion took  0.22365045547485352  time\n",
      "insertion took  0.2178659439086914  time\n",
      "insertion took  0.21875882148742676  time\n",
      "insertion took  0.21797513961791992  time\n",
      "insertion took  0.2164449691772461  time\n",
      "insertion took  0.2208690643310547  time\n",
      "insertion took  0.22219300270080566  time\n",
      "insertion took  0.22235441207885742  time\n",
      "insertion took  0.22153282165527344  time\n",
      "insertion took  0.22009825706481934  time\n",
      "insertion took  0.22089529037475586  time\n",
      "insertion took  0.22297883033752441  time\n",
      "insertion took  0.22463726997375488  time\n",
      "insertion took  0.22087931632995605  time\n",
      "insertion took  0.22320079803466797  time\n",
      "insertion took  0.22197318077087402  time\n",
      "insertion took  0.22109603881835938  time\n",
      "insertion took  0.22318148612976074  time\n",
      "insertion took  0.22063183784484863  time\n",
      "insertion took  0.22243428230285645  time\n",
      "insertion took  0.2193143367767334  time\n",
      "insertion took  0.22090387344360352  time\n",
      "insertion took  0.22415494918823242  time\n",
      "insertion took  0.2213735580444336  time\n",
      "insertion took  0.22186851501464844  time\n",
      "insertion took  0.22066354751586914  time\n",
      "insertion took  0.21866917610168457  time\n",
      "insertion took  0.219207763671875  time\n",
      "insertion took  0.21924805641174316  time\n",
      "insertion took  0.21903634071350098  time\n",
      "insertion took  0.21860456466674805  time\n",
      "insertion took  0.2203505039215088  time\n",
      "insertion took  0.21808862686157227  time\n",
      "insertion took  0.22157740592956543  time\n",
      "insertion took  0.2241377830505371  time\n",
      "insertion took  0.22155308723449707  time\n",
      "insertion took  0.22683095932006836  time\n",
      "insertion took  0.23035407066345215  time\n",
      "insertion took  0.22141575813293457  time\n",
      "insertion took  0.22866368293762207  time\n",
      "insertion took  0.22141504287719727  time\n",
      "insertion took  0.22529053688049316  time\n",
      "insertion took  0.22590899467468262  time\n",
      "insertion took  0.2365727424621582  time\n",
      "insertion took  0.2279987335205078  time\n",
      "insertion took  0.23136115074157715  time\n",
      "insertion took  0.21903586387634277  time\n",
      "insertion took  0.23414897918701172  time\n",
      "insertion took  0.22455739974975586  time\n",
      "insertion took  0.23284602165222168  time\n",
      "insertion took  0.22056221961975098  time\n",
      "insertion took  0.22257733345031738  time\n",
      "insertion took  0.21869635581970215  time\n",
      "insertion took  0.2211005687713623  time\n",
      "insertion took  0.22278618812561035  time\n",
      "insertion took  0.21541476249694824  time\n",
      "insertion took  0.221174955368042  time\n",
      "insertion took  0.2250378131866455  time\n",
      "insertion took  0.21975398063659668  time\n",
      "insertion took  0.22688961029052734  time\n",
      "insertion took  0.22176170349121094  time\n",
      "insertion took  0.22005581855773926  time\n",
      "insertion took  0.22286152839660645  time\n",
      "insertion took  0.22521543502807617  time\n",
      "insertion took  0.2253727912902832  time\n",
      "insertion took  0.23330187797546387  time\n",
      "insertion took  0.23075604438781738  time\n",
      "insertion took  0.21586871147155762  time\n",
      "insertion took  0.22135591506958008  time\n",
      "insertion took  0.22011518478393555  time\n",
      "insertion took  0.21645712852478027  time\n",
      "insertion took  0.21716952323913574  time\n",
      "insertion took  0.21734380722045898  time\n",
      "insertion took  0.2151634693145752  time\n",
      "insertion took  0.21715664863586426  time\n",
      "insertion took  0.2174534797668457  time\n",
      "insertion took  0.21636533737182617  time\n",
      "insertion took  0.2163224220275879  time\n",
      "insertion took  0.21604657173156738  time\n",
      "insertion took  0.21550989151000977  time\n",
      "insertion took  0.21676182746887207  time\n",
      "insertion took  0.21901583671569824  time\n",
      "insertion took  0.21704411506652832  time\n",
      "insertion took  0.21558713912963867  time\n",
      "insertion took  0.21775293350219727  time\n",
      "insertion took  0.2151808738708496  time\n",
      "insertion took  0.21729111671447754  time\n",
      "insertion took  0.21835923194885254  time\n",
      "insertion took  0.21666789054870605  time\n",
      "insertion took  0.2174057960510254  time\n",
      "insertion took  0.2248687744140625  time\n",
      "insertion took  0.21953845024108887  time\n",
      "insertion took  0.2190239429473877  time\n",
      "insertion took  0.21924161911010742  time\n",
      "Time taken: 51.06434655189514\n",
      "accuracy:  0.6043478260869565\n",
      "insertion took  0.216386079788208  time\n",
      "insertion took  0.2440955638885498  time\n",
      "insertion took  0.21910309791564941  time\n",
      "insertion took  0.21729445457458496  time\n",
      "insertion took  0.21903443336486816  time\n",
      "insertion took  0.21884846687316895  time\n",
      "insertion took  0.22005295753479004  time\n",
      "insertion took  0.21660780906677246  time\n",
      "insertion took  0.21959805488586426  time\n",
      "insertion took  0.21956849098205566  time\n",
      "insertion took  0.21776580810546875  time\n",
      "insertion took  0.22050809860229492  time\n",
      "insertion took  0.22118067741394043  time\n",
      "insertion took  0.22006869316101074  time\n",
      "insertion took  0.2231435775756836  time\n",
      "insertion took  0.22824597358703613  time\n",
      "insertion took  0.22585725784301758  time\n",
      "insertion took  0.22241663932800293  time\n",
      "insertion took  0.22394680976867676  time\n",
      "insertion took  0.22945380210876465  time\n",
      "insertion took  0.22287797927856445  time\n",
      "insertion took  0.22485089302062988  time\n",
      "insertion took  0.2242574691772461  time\n",
      "insertion took  0.2251429557800293  time\n",
      "insertion took  0.22265625  time\n",
      "insertion took  0.2194685935974121  time\n",
      "insertion took  0.22187519073486328  time\n",
      "insertion took  0.21973967552185059  time\n",
      "insertion took  0.21805262565612793  time\n",
      "insertion took  0.2221696376800537  time\n",
      "insertion took  0.2280879020690918  time\n",
      "insertion took  0.22487616539001465  time\n",
      "insertion took  0.2193901538848877  time\n",
      "insertion took  0.22228312492370605  time\n",
      "insertion took  0.21728801727294922  time\n",
      "insertion took  0.22463250160217285  time\n",
      "insertion took  0.22197294235229492  time\n",
      "insertion took  0.21745991706848145  time\n",
      "insertion took  0.21969985961914062  time\n",
      "insertion took  0.21955370903015137  time\n",
      "insertion took  0.2192549705505371  time\n",
      "insertion took  0.21900224685668945  time\n",
      "insertion took  0.2213907241821289  time\n",
      "insertion took  0.21854734420776367  time\n",
      "insertion took  0.2196638584136963  time\n",
      "insertion took  0.22112584114074707  time\n",
      "insertion took  0.2188577651977539  time\n",
      "insertion took  0.2209007740020752  time\n",
      "insertion took  0.22021746635437012  time\n",
      "insertion took  0.2196025848388672  time\n",
      "insertion took  0.246612548828125  time\n",
      "insertion took  0.24434375762939453  time\n",
      "insertion took  0.24173808097839355  time\n",
      "insertion took  0.22897100448608398  time\n",
      "insertion took  0.23833060264587402  time\n",
      "insertion took  0.22791147232055664  time\n",
      "insertion took  0.2237083911895752  time\n",
      "insertion took  0.22083544731140137  time\n",
      "insertion took  0.22803974151611328  time\n",
      "insertion took  0.23351812362670898  time\n",
      "insertion took  0.2680671215057373  time\n",
      "insertion took  0.26599693298339844  time\n",
      "insertion took  0.25125575065612793  time\n",
      "insertion took  0.22914528846740723  time\n",
      "insertion took  0.2261219024658203  time\n",
      "insertion took  0.2250995635986328  time\n",
      "insertion took  0.22686290740966797  time\n",
      "insertion took  0.2205038070678711  time\n",
      "insertion took  0.21947813034057617  time\n",
      "insertion took  0.22646379470825195  time\n",
      "insertion took  0.22959423065185547  time\n",
      "insertion took  0.22517180442810059  time\n",
      "insertion took  0.227463960647583  time\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "insertion took  0.2678980827331543  time\n",
      "insertion took  0.22784948348999023  time\n",
      "insertion took  0.23471999168395996  time\n",
      "insertion took  0.23099637031555176  time\n",
      "insertion took  0.24248623847961426  time\n",
      "insertion took  0.21886658668518066  time\n",
      "insertion took  0.22232651710510254  time\n",
      "insertion took  0.23084759712219238  time\n",
      "insertion took  0.23801946640014648  time\n",
      "insertion took  0.2206408977508545  time\n",
      "insertion took  0.2226407527923584  time\n",
      "insertion took  0.23557305335998535  time\n",
      "insertion took  0.2181870937347412  time\n",
      "insertion took  0.22331023216247559  time\n",
      "insertion took  0.22356772422790527  time\n",
      "insertion took  0.22353792190551758  time\n",
      "insertion took  0.22218608856201172  time\n",
      "insertion took  0.21824002265930176  time\n",
      "insertion took  0.21749591827392578  time\n",
      "insertion took  0.2180929183959961  time\n",
      "insertion took  0.2192072868347168  time\n",
      "insertion took  0.21754193305969238  time\n",
      "insertion took  0.22422504425048828  time\n",
      "insertion took  0.21959662437438965  time\n",
      "insertion took  0.2229621410369873  time\n",
      "insertion took  0.22873497009277344  time\n",
      "insertion took  0.22203350067138672  time\n",
      "insertion took  0.21692395210266113  time\n",
      "insertion took  0.2187206745147705  time\n",
      "insertion took  0.22118878364562988  time\n",
      "insertion took  0.21887469291687012  time\n",
      "insertion took  0.21712708473205566  time\n",
      "insertion took  0.21997761726379395  time\n",
      "insertion took  0.21962332725524902  time\n",
      "insertion took  0.21690011024475098  time\n",
      "insertion took  0.21932339668273926  time\n",
      "insertion took  0.21820592880249023  time\n",
      "insertion took  0.2179715633392334  time\n",
      "insertion took  0.22077703475952148  time\n",
      "insertion took  0.221879243850708  time\n",
      "insertion took  0.22185182571411133  time\n",
      "insertion took  0.21653151512145996  time\n",
      "insertion took  0.22148990631103516  time\n",
      "insertion took  0.2244553565979004  time\n",
      "insertion took  0.2261817455291748  time\n",
      "insertion took  0.21774983406066895  time\n",
      "insertion took  0.22243523597717285  time\n",
      "insertion took  0.22408366203308105  time\n",
      "insertion took  0.21681451797485352  time\n",
      "insertion took  0.2243053913116455  time\n",
      "insertion took  0.22074484825134277  time\n",
      "insertion took  0.2165219783782959  time\n",
      "insertion took  0.22139406204223633  time\n",
      "insertion took  0.22285890579223633  time\n",
      "insertion took  0.2189924716949463  time\n",
      "insertion took  0.2205040454864502  time\n",
      "insertion took  0.22586894035339355  time\n",
      "insertion took  0.21836256980895996  time\n",
      "insertion took  0.22011733055114746  time\n",
      "insertion took  0.22235989570617676  time\n",
      "insertion took  0.2169325351715088  time\n",
      "insertion took  0.21956682205200195  time\n",
      "insertion took  0.21934771537780762  time\n",
      "insertion took  0.21581172943115234  time\n",
      "insertion took  0.21771931648254395  time\n",
      "insertion took  0.218017578125  time\n",
      "insertion took  0.2180006504058838  time\n",
      "insertion took  0.22016453742980957  time\n",
      "insertion took  0.2181396484375  time\n",
      "insertion took  0.2167367935180664  time\n",
      "insertion took  0.21944737434387207  time\n",
      "insertion took  0.2192981243133545  time\n",
      "insertion took  0.2166731357574463  time\n",
      "insertion took  0.2200615406036377  time\n",
      "insertion took  0.2182321548461914  time\n",
      "insertion took  0.21642160415649414  time\n",
      "insertion took  0.22114133834838867  time\n",
      "insertion took  0.2225656509399414  time\n",
      "insertion took  0.21859073638916016  time\n",
      "insertion took  0.2169036865234375  time\n",
      "insertion took  0.2164628505706787  time\n",
      "insertion took  0.21903681755065918  time\n",
      "insertion took  0.2197427749633789  time\n",
      "insertion took  0.2187507152557373  time\n",
      "insertion took  0.22060537338256836  time\n",
      "insertion took  0.22034716606140137  time\n",
      "insertion took  0.21806979179382324  time\n",
      "insertion took  0.218658447265625  time\n",
      "insertion took  0.22128772735595703  time\n",
      "insertion took  0.21908879280090332  time\n",
      "insertion took  0.22063374519348145  time\n",
      "insertion took  0.22265315055847168  time\n",
      "insertion took  0.21817970275878906  time\n",
      "insertion took  0.2210226058959961  time\n",
      "insertion took  0.22043156623840332  time\n",
      "insertion took  0.2194836139678955  time\n",
      "insertion took  0.21974706649780273  time\n",
      "insertion took  0.2201244831085205  time\n",
      "insertion took  0.21788525581359863  time\n",
      "insertion took  0.2188875675201416  time\n",
      "insertion took  0.22070789337158203  time\n",
      "insertion took  0.21713972091674805  time\n",
      "insertion took  0.22197341918945312  time\n",
      "insertion took  0.2213590145111084  time\n",
      "insertion took  0.21885037422180176  time\n",
      "insertion took  0.22066116333007812  time\n",
      "insertion took  0.2200331687927246  time\n",
      "insertion took  0.2200911045074463  time\n",
      "insertion took  0.21910452842712402  time\n",
      "insertion took  0.22029685974121094  time\n",
      "insertion took  0.21851015090942383  time\n",
      "insertion took  0.2205212116241455  time\n",
      "insertion took  0.22098326683044434  time\n",
      "insertion took  0.21708917617797852  time\n",
      "insertion took  0.22021102905273438  time\n",
      "insertion took  0.22152090072631836  time\n",
      "insertion took  0.2180156707763672  time\n",
      "insertion took  0.22113800048828125  time\n",
      "insertion took  0.2229604721069336  time\n",
      "insertion took  0.22302746772766113  time\n",
      "insertion took  0.22329044342041016  time\n",
      "insertion took  0.22045326232910156  time\n",
      "insertion took  0.218369722366333  time\n",
      "insertion took  0.21796321868896484  time\n",
      "insertion took  0.22069644927978516  time\n",
      "insertion took  0.21755671501159668  time\n",
      "insertion took  0.22020769119262695  time\n",
      "insertion took  0.21877050399780273  time\n",
      "insertion took  0.21734356880187988  time\n",
      "insertion took  0.21982908248901367  time\n",
      "insertion took  0.22020316123962402  time\n",
      "insertion took  0.2200019359588623  time\n",
      "insertion took  0.22037053108215332  time\n",
      "insertion took  0.22029924392700195  time\n",
      "insertion took  0.21872425079345703  time\n",
      "insertion took  0.22371387481689453  time\n",
      "insertion took  0.22167515754699707  time\n",
      "insertion took  0.21962404251098633  time\n",
      "insertion took  0.22005558013916016  time\n",
      "insertion took  0.2198636531829834  time\n",
      "insertion took  0.21886539459228516  time\n",
      "insertion took  0.21876883506774902  time\n",
      "insertion took  0.2223038673400879  time\n",
      "insertion took  0.22136139869689941  time\n",
      "insertion took  0.21860790252685547  time\n",
      "insertion took  0.21878361701965332  time\n",
      "insertion took  0.22122526168823242  time\n",
      "insertion took  0.21779441833496094  time\n",
      "insertion took  0.2201099395751953  time\n",
      "insertion took  0.21991419792175293  time\n",
      "insertion took  0.21824359893798828  time\n",
      "insertion took  0.2232048511505127  time\n",
      "insertion took  0.22941017150878906  time\n",
      "insertion took  0.2256004810333252  time\n",
      "insertion took  0.21800923347473145  time\n",
      "insertion took  0.225541353225708  time\n",
      "insertion took  0.22381329536437988  time\n",
      "Time taken: 51.196980476379395\n",
      "accuracy:  0.6260869565217392\n",
      "insertion took  0.21964287757873535  time\n",
      "insertion took  0.2251605987548828  time\n",
      "insertion took  0.2265033721923828  time\n",
      "insertion took  0.22646856307983398  time\n",
      "insertion took  0.21845364570617676  time\n",
      "insertion took  0.2294771671295166  time\n",
      "insertion took  0.22623610496520996  time\n",
      "insertion took  0.21800661087036133  time\n",
      "insertion took  0.2260587215423584  time\n",
      "insertion took  0.22568941116333008  time\n",
      "insertion took  0.21889781951904297  time\n",
      "insertion took  0.22355246543884277  time\n",
      "insertion took  0.22379112243652344  time\n",
      "insertion took  0.2193012237548828  time\n",
      "insertion took  0.22029829025268555  time\n",
      "insertion took  0.22101378440856934  time\n",
      "insertion took  0.21924352645874023  time\n",
      "insertion took  0.22074103355407715  time\n",
      "insertion took  0.22012662887573242  time\n",
      "insertion took  0.21786212921142578  time\n",
      "insertion took  0.2206737995147705  time\n",
      "insertion took  0.22302842140197754  time\n",
      "insertion took  0.2219409942626953  time\n",
      "insertion took  0.21930408477783203  time\n",
      "insertion took  0.22182941436767578  time\n",
      "insertion took  0.21817684173583984  time\n",
      "insertion took  0.22088336944580078  time\n",
      "insertion took  0.2219381332397461  time\n",
      "insertion took  0.22141480445861816  time\n",
      "insertion took  0.22025537490844727  time\n",
      "insertion took  0.22015166282653809  time\n",
      "insertion took  0.22178030014038086  time\n",
      "insertion took  0.22111177444458008  time\n",
      "insertion took  0.22424745559692383  time\n",
      "insertion took  0.22219061851501465  time\n",
      "insertion took  0.2205345630645752  time\n",
      "insertion took  0.22239279747009277  time\n",
      "insertion took  0.218705415725708  time\n",
      "insertion took  0.2191615104675293  time\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "insertion took  0.22176694869995117  time\n",
      "insertion took  0.21933889389038086  time\n",
      "insertion took  0.22230219841003418  time\n",
      "insertion took  0.2241063117980957  time\n",
      "insertion took  0.2202444076538086  time\n",
      "insertion took  0.22180724143981934  time\n",
      "insertion took  0.22394824028015137  time\n"
     ]
    }
   ],
   "source": [
    "# your code goes here\n",
    "test_set_len = len(knn_data) // 5\n",
    "d = defaultdict(list)\n",
    "\n",
    "for i in range(5):\n",
    "# partition data into train_set and test_set\n",
    "    train_set = knn_data[0:i * test_set_len].append(knn_data[(i + 1) * test_set_len:len(knn_data)])\n",
    "    print(train_set.head())\n",
    "    test_set = knn_data[i * test_set_len:(i + 1) * test_set_len]\n",
    "    print(test_set.head())\n",
    "    print ('Training set size:', len(train_set))\n",
    "    print ('Test set size    :', len(test_set))\n",
    "    for j in range(1, 10, 2):\n",
    "        knn = KNN(train_set, j)\n",
    "    \n",
    "        start = time.time()\n",
    "        acc = calcAccuracy(knn, test_set)\n",
    "        end = time.time()\n",
    "        print ('Time taken:', end - start)\n",
    "        d[j].append(acc)\n",
    "        print(\"accuracy: \", acc)\n",
    "\"\"\"\n",
    "d[1] = [.5739130434782609, 0.6130434782608696, 0.6260869565217392, 0.6478260869565218, 0.591304347826087]\n",
    "d[3] = [.6391304347826087, 0.6173913043478261, 0.6260869565217392, 0.6434782608695652, 0.6043478260869565]\n",
    "d[5] = [.6173913043478261, 0.5782608695652174, 0.6521739130434783, 0.6260869565217392, 0.6260869565217392]\n",
    "d[7] = [0.6434782608695652, 0.6043478260869565, 0.6826086956521739, 0.6434782608695652, 0.6130434782608696]\n",
    "d[9] = [0.6782608695652174, 0.6, 0.6695652173913044, 0.6565217391304348, 0.591304347826087]\n",
    "\"\"\"\n",
    "avg_accs = []\n",
    "for k, accuracies in d.items():\n",
    "    avg_accs.append((k, sum(accuracies) / len(accuracies)))\n",
    "    \n",
    "labels = ['k', 'average accuracy']\n",
    "new_data_f = pd.DataFrame(data=avg_accs, columns=labels)\n",
    "new_data_f.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data_f.plot.line(x=\"k\", y=\"average accuracy\")\n",
    "\"\"\"\n",
    "best value of k is 9, it has the highest average accuracy across 5 fold validation\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q5. Now measure the accuracy of your classifier using 5-fold cross validation. In each fold of this CV, divide your data into a training set and a test set. The training set should get sent through your code for Q4, resulting in a value of k to use. Using that k, calculate an accuracy on the test set. You will average the accuracy over all 5 folds to obtain the final accuracy measurement. Print the accuracy as well as the precision and recall for class label 1 (patients that have been diagnosed with the disease)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code goes here\n",
    "accs = []\n",
    "for i in range(5):\n",
    "# partition data into train_set and test_set\n",
    "    train_set = knn_data[0:i * test_set_len].append(knn_data[(i + 1) * test_set_len:len(knn_data)])\n",
    "    test_set = knn_data[i * test_set_len:(i + 1) * test_set_len]\n",
    "    knn = KNN(train_set, 9)\n",
    "    acc = calcAccuracy(knn, test_set)\n",
    "    accs.append(acc)\n",
    "    print(\"fold: \", i, \" accuracy: \", acc)\n",
    "avg_acc = sum(accs) / len(accs)\n",
    "print(\"Average accuracy for 9-NN: \", avg_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To explore further:\n",
    "\n",
    "1) Use scikit-learn's NearestNeighbor classifier to classify the data. Compare those results to your own. The documentation can be found [here](http://scikit-learn.org/stable/modules/neighbors.html), specifically section 1.6.2 and the link to the [KNeighborsClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier).\n",
    "\n",
    "2) Use scikit-learn's Naive Bayes classifier to classify the data. Compare those results to your own. The documentation is found [here](http://scikit-learn.org/stable/modules/naive_bayes.html), specifically section 1.9.2 and the link to [MultinomialNB](http://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html#sklearn.naive_bayes.MultinomialNB). You will want to bin the continuous attributes, as you did above, and consider each bin to be a categorical value for that attribute. For example, feature 5 ranges from [1 - 120], and the 3 bins that you'll construct will be [1 - 40], [41 - 80], [81 - 120]. You can think of this as saying that feature 5 can take 1 of 3 values: low, med, or high. With binning, you have transformed all of your features into categorical features and the MultinomialNB version of Naive Bayes is what should be used for all categorical data. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
